# Geo-Flow VLA Configuration
# Hydra-compatible YAML configuration for all training and model parameters

defaults:
  - _self_

# ============================================================================
# Model Architecture
# ============================================================================
model:
  # State representation dimensions
  state_dim: 512              # Fused state embedding dimension
  semantic_dim: 1536          # DINOv2-G output dimension
  geometric_dim: 256          # MoGe point feature projection dim
  
  # Action space
  action_dim: 7               # 7-DoF: xyz + axis-angle rotation + gripper
  action_horizon: 16          # Number of action steps to predict
  
  # DiT (Diffusion Transformer) architecture
  dit:
    hidden_dim: 768           # Transformer hidden dimension
    num_layers: 12            # Number of transformer blocks
    num_heads: 12             # Number of attention heads
    mlp_ratio: 4.0            # MLP expansion ratio
    dropout: 0.15             # Dropout rate (increased for regularization)
    
  # Forward-Backward World Model
  fb:
    latent_dim: 256           # Dimension of z (on unit sphere)
    hidden_dim: 512           # Hidden dimension for F and B networks
    num_residual_blocks: 2    # Number of residual blocks in F
    ema_tau: 0.005            # EMA update rate for target network
    
  # Discriminator for CPR
  discriminator:
    hidden_dim: 512
    num_layers: 3
    gradient_penalty: 10.0    # Weight for gradient penalty

# ============================================================================
# Vision Encoders (Frozen)
# ============================================================================
encoders:
  # DINOv2-G/14 for semantic features
  dinov2:
    model_name: "dinov2_vitg14"
    pretrained: true
    frozen: true
    
  # MoGe-2 for 3D geometry
  moge:
    model_name: "Ruicheng/moge-2-vitl-normal"
    pretrained: true
    frozen: true
    use_mock: false           # Set true if MoGe weights unavailable

# ============================================================================
# Data Configuration
# ============================================================================
data:
  # Image preprocessing
  image_size: 224
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]
  
  # Dataset selection
  dataset: "libero"           # Options: libero, rlbench, calvin
  libero_suite: "full"         # Options: spatial, object, goal, 10, 90, 100 (long), all, full
  
  # Data loading
  num_workers: 1              # Reduce if getting shm/bus errors
  pin_memory: true
  prefetch_factor: 1
  
  # Action chunking
  chunk_size: 16              # Number of actions per chunk
  overlap: 8                  # Overlap between consecutive chunks
  
  # Data paths
  data_root: "./data/libero"
  cache_dir: "./cache"

# ============================================================================
# Training Configuration
# ============================================================================
training:
  # Phase 1: World Model (FB) Training
  phase1:
    epochs: 100
    batch_size: 64
    lr: 1.0e-4
    weight_decay: 1.0e-5
    warmup_steps: 1000
    gradient_clip: 1.0
    
    # FB loss weights
    forward_weight: 1.0
    backward_weight: 0.5      # Î² in the plan
    
    # Checkpointing
    save_every: 5             # Save checkpoint every N epochs
    eval_every: 1             # Evaluate every N epochs
    
  # Phase 2: Policy Training
  phase2:
    epochs: 200
    batch_size: 64
    lr_policy: 3.0e-5
    lr_discriminator: 1.0e-4
    weight_decay: 5.0e-5      # Increased for regularization (was 1.0e-5)
    warmup_steps: 2000
    gradient_clip: 1.0
    
    # World model checkpoint
    world_model_path: null    # Path to world model; null = auto-detect from checkpoint.dir/phase1/
    
    # CPR parameters
    cpr_lambda_start: 0.0     # Initial CPR weight
    cpr_lambda_end: 0.1       # Final CPR weight
    cpr_warmup_epochs: 20     # Epochs to warm up CPR
    discriminator_steps: 1    # Discriminator updates per policy update
    
    # Flow matching
    schedule: "linear"        # Options: linear, cosine, ot
    num_inference_steps: 50   # Steps for inference sampling
    
    # Early stopping to prevent overfitting
    early_stopping: true
    early_stopping_patience: 15    # Stop if no improvement for N epochs
    early_stopping_min_delta: 0.001  # Minimum improvement threshold
    
    # Checkpointing
    save_every: 5
    eval_every: 1

# ============================================================================
# Augmentation
# ============================================================================
augmentation:
  enabled: true
  
  # SE(3) augmentation
  rotation_range: 0.15        # Enable rotation augmentation (radians)
  translation_range: 0.15     # Translation range in meters (increased)
  
  # Color jitter augmentation
  color_jitter: true          # Enable color augmentation
  color_jitter_brightness: 0.2
  color_jitter_contrast: 0.2
  color_jitter_saturation: 0.2
  color_jitter_hue: 0.05
  
  # Random crop augmentation
  random_crop: true           # Enable random crop
  crop_scale_min: 0.85        # Minimum crop scale
  crop_scale_max: 1.0         # Maximum crop scale

# ============================================================================
# Logging and Checkpointing
# ============================================================================
logging:
  # Weights & Biases
  wandb:
    enabled: true
    project: "geo-flow-vla"
    entity: null              # Set your W&B entity/team
    name: null                # Run name (auto-generated if null)
    tags: []
    group: null               # Experiment group
    save_code: true
    
  # Local logging
  log_dir: "./logs"
  log_every: 1              # Log metrics every N steps
  
  # Visualization
  vis_every: 1                # Visualize every N epochs
  num_vis_samples: 1          # Number of samples to visualize
  save_videos: true           # Save evaluation rollout videos

# ============================================================================
# Checkpointing
# ============================================================================
checkpoint:
  dir: "./checkpoints/libero/original+aug/${data.libero_suite}/"
  resume: null                # Path to checkpoint to resume from
  save_best: true             # Save best model based on eval metric
  keep_last: 3                # Keep last N checkpoints

# ============================================================================
# Hardware Configuration
# ============================================================================
hardware:
  device: "cuda"
  precision: "bf16"           # Options: fp32, fp16, bf16
  compile: false              # torch.compile for PyTorch 2.0+
  seed: 42
  
  # Distributed training (Multi-GPU)
  distributed: false          # Enable multi-GPU training
  num_gpus: 1                 # Number of GPUs (auto-detected if using torchrun)
  backend: "nccl"             # Distributed backend: nccl, gloo
  find_unused_params: false   # Set true if model has unused parameters

# ============================================================================
# Evaluation
# ============================================================================
evaluation:
  num_episodes: 50            # Episodes per task for evaluation
  max_episode_length: 300     # Maximum steps per episode
  record_video: true
  video_fps: 30

